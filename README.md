# ğŸ§  My AI PKB â€“ Local AI-Powered Knowledge Base

This is a lightweight, fully local system for managing your personal knowledge with the support of an AI language model. It combines Markdown files, embeddings, a local LLM, and a web interface for semantic search and interaction.

**This project is an early PoC, do not use in production!**

---

## ğŸš€ Features

- ğŸ“ Storage in Markdown files  
- ğŸ“š Embedding with Sentence Transformers  
- ğŸ” Semantic search using Chroma DB  
- ğŸ§  LLM integration via Mistral 7B with Ollama  
- ğŸ—£ï¸ Voice input using Whisper (optional)  
- ğŸ–¥ï¸ Web frontend with Streamlit  
- ğŸ”Œ RAG integration via LangChain  

---

## ğŸ“¦ Project Structure

```
my-ai-pkb/
â”œâ”€â”€ data/            # Your Markdown notes
â”œâ”€â”€ embeddings/      # Chroma vector database
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ embedder.py      # Creates embeddings from Markdown files
â”‚   â”œâ”€â”€ rag.py           # Retrieval + LLM response
â”‚   â”œâ”€â”€ whisper_input.py # Voice recording & transcription (optional)
â”‚   â””â”€â”€ ui.py            # Streamlit UI
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Installation

### 1. Prerequisites

- Python 3.10+  
- [Ollama](https://ollama.com/) installed and running  
- ffmpeg for Whisper (e.g., `sudo apt install ffmpeg`)  

### 2. Setup

```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

## âš™ï¸ Usage

### 1. Start the Mistral LLM via Ollama

```bash
ollama serve
ollama run mistral
```

### 2. Index your notes

```bash
python app/embedder.py
```

### 3. Launch the UI

```bash
streamlit run app/ui.py
```

---

## ğŸ¤ Voice Interface (optional)

```bash
python app/whisper_input.py
```

> Uses Whisper for speech-to-text transcription.

---

## ğŸ”’ Privacy

All data and models run **locally** â€“ no cloud, no tracking.

---

## ğŸ“ Roadmap

- ğŸ” Automatic re-indexing via Git hook  
- ğŸ§¾ YAML metadata for Markdown files  
- ğŸ“„ PDF/OCR support  
- ğŸ—£ï¸ Voice output with Coqui TTS  
